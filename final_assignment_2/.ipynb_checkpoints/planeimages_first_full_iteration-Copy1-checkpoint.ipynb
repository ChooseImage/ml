{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "from skimage import io, color, transform, feature, filters\n",
    "from my_measures import BinaryClassificationPerformance  \n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "from skimage.feature import corner_foerstner, corner_peaks\n",
    "from skimage.color import rgb2gray\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT!!! Make sure you are using BinaryClassificationPerformance v1.03\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(BinaryClassificationPerformance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### file paths and names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_path = 'plane_data/cropped_images/' # file path for cropped images for training\n",
    "l_file = 'plane_data/plane_labels.csv' # file path and file name for csv with labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for feature building and extraction on photographsÂ¶\n",
    "\n",
    "scikit-image documentation on methods used for feature extraction:  \n",
    "\n",
    "* http://scikit-image.org/docs/dev/api/skimage.color.html#rgb2gray  \n",
    "* http://scikit-image.org/docs/dev/api/skimage.transform.html#skimage.transform.resize  \n",
    "* http://scikit-image.org/docs/stable/api/skimage.feature.html#skimage.feature.canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in downscaling the image, what do you want the new dimensions to be?\n",
    "# the original dimensions of cropped images: (60, 140), which if 8,400 pixels\n",
    "dims = (15, 35) # 25% of the original size, 525 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downscaled image shape: \n",
      "(15, 35)\n",
      "<class 'numpy.ndarray'>\n",
      "image representation (first row of pixels): \n",
      "[0.03051241 0.02850514 0.01116356 0.00857712 0.00854595 0.00632196\n",
      " 0.00381023 0.00200308 0.00177744 0.00237866 0.00330992 0.00415537\n",
      " 0.00385634 0.00212913 0.00122013 0.00159046 0.00253638 0.00437637\n",
      " 0.00472544 0.00477062 0.00782447 0.00968618 0.00734184 0.0037378\n",
      " 0.00180091 0.00252996 0.00695759 0.0143008  0.02646284 0.04534141\n",
      " 0.04497569 0.02738399 0.02423789 0.0399285  0.03955277]\n",
      "\n",
      "\n",
      "example of transformation: \n"
     ]
    }
   ],
   "source": [
    "def image_manipulation(imname, imgs_path, imview=False):\n",
    "    warnings.filterwarnings('ignore')\n",
    "    imname = imgs_path + imname + '.png'\n",
    "    img_raw = io.imread(imname, as_gray=True)\n",
    "    downscaled = transform.resize(img_raw, (dims[0], dims[1])) # downscale image\n",
    "    \n",
    "    \n",
    "    final_image = feature.corner_harris(downscaled) \n",
    "\n",
    "    final_image = feature.corner_shi_tomasi(downscaled, sigma=1) \n",
    "    #final_image = feature.canny(final_image) # edge filter image with Canny algorithm\n",
    "   \n",
    "    \n",
    "    if imview==True:\n",
    "        plt.figure()\n",
    "        plt.imshow(final_image, cmap='Greys')\n",
    "        plt.show()\n",
    "    warnings.filterwarnings('always')\n",
    "    return final_image\n",
    "\n",
    "# test the function, look at input/output\n",
    "test_image = image_manipulation('2017-08-25T23+24+13_390Z', ci_path, True)\n",
    "print('downscaled image shape: ')\n",
    "print(test_image.shape)\n",
    "print(type(test_image))\n",
    "print('image representation (first row of pixels): ')\n",
    "print(test_image[0])\n",
    "print('\\n')\n",
    "print('example of transformation: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for comparison, look at original image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#this_imname = ci_path + '2017-08-25T23+24+13_390Z.png'\n",
    "#io.imshow(io.imread(this_imname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function to process raw images, resulting in training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes raw images and completes all preprocessing required before model fits\n",
    "def process_raw_data(labels_fn, images_fp, my_random_seed, imview=False, test=False):\n",
    "    plane_data = pd.read_csv(labels_fn) # read in photograph labels\n",
    "    print(\"First few lines of image labels: \")\n",
    "    print(plane_data.head())\n",
    "    print(\"Size of image label dataFrame: \")\n",
    "    print(plane_data.shape)\n",
    "        \n",
    "    # construct lists for features, labels, and a crosswalk reference to image names\n",
    "    features_list = []\n",
    "    if (not test):\n",
    "        y_list = []\n",
    "    imnames_list = []\n",
    "\n",
    "    for index, row in plane_data.iterrows():\n",
    "        features_list.append(image_manipulation(row['img_name'], images_fp))\n",
    "        if (not test):\n",
    "            y_list.append(row['plane'])\n",
    "        imnames_list.append(row['img_name'])\n",
    "    \n",
    "    # convert the lists to ndarrays\n",
    "    features = np.asarray(features_list)\n",
    "    if (not test):\n",
    "        Y = np.asarray(y_list)\n",
    "    imgs = np.asarray(imnames_list)\n",
    "    print('Shape of original feature representation: ')\n",
    "    print(features.shape)\n",
    "\n",
    "    # flatten the images ndarray to one row per image\n",
    "    features_flat = features.reshape((features.shape[0], -1))\n",
    "\n",
    "    print('Shape of flat feature representation: ')\n",
    "    print(features_flat.shape)\n",
    "\n",
    "    if (not test):\n",
    "        print('Shape of Y: ')\n",
    "        print(Y.shape)\n",
    "\n",
    "        print('Number of images with planes: ')\n",
    "        print(Y.sum())\n",
    "    \n",
    "        # create train and test sets\n",
    "        data_train, data_test, y_train, y_test, imgs_train, imgs_test = train_test_split(features_flat, \n",
    "            Y, imgs, test_size = 0.25, random_state = my_random_seed)\n",
    "\n",
    "        print('Shape of training set: ')\n",
    "        print(y_train.shape)\n",
    "        print('Number of training images that contain an airplane: ')\n",
    "        print(y_train.sum())\n",
    "\n",
    "        print('Shape of test set: ')\n",
    "        print(y_test.shape)\n",
    "        print('Number of test images that contain an airplane: ')\n",
    "        print(y_test.sum())\n",
    "    \n",
    "    if (test):\n",
    "        X_submission_test = features_flat\n",
    "        print(\"Shape of X_test for submission:\")\n",
    "        print(X_submission_test.shape)\n",
    "        print('SUCCESS!')\n",
    "        return(X_submission_test, plane_data)\n",
    "    else: \n",
    "        print(\"Shape of data_train and data_test:\")\n",
    "        print(data_train.shape)\n",
    "        print(data_test.shape)\n",
    "        print(\"Shape of y_train and y_test:\")\n",
    "        print(y_train.shape)\n",
    "        print(y_test.shape)\n",
    "        print(\"Shape of imgs_train and imgs_test:\")\n",
    "        print(imgs_train.shape)\n",
    "        print(imgs_test.shape)\n",
    "        print('SUCCESS!')\n",
    "        return(data_train, data_test, y_train, y_test, imgs_train, imgs_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few lines of image labels: \n",
      "                   img_name  plane\n",
      "0  2016-08-02T13+50+24_430Z  False\n",
      "1  2016-08-02T14+12+37_390Z  False\n",
      "2  2016-08-02T22+20+26_600Z  False\n",
      "3  2016-08-03T12+04+30_670Z  False\n",
      "4  2016-08-03T12+32+21_790Z  False\n",
      "Size of image label dataFrame: \n",
      "(6758, 2)\n",
      "Shape of original feature representation: \n",
      "(6758, 15, 35)\n",
      "Shape of flat feature representation: \n",
      "(6758, 525)\n",
      "Shape of Y: \n",
      "(6758,)\n",
      "Number of images with planes: \n",
      "101\n",
      "Shape of training set: \n",
      "(5068,)\n",
      "Number of training images that contain an airplane: \n",
      "76\n",
      "Shape of test set: \n",
      "(1690,)\n",
      "Number of test images that contain an airplane: \n",
      "25\n",
      "Shape of data_train and data_test:\n",
      "(5068, 525)\n",
      "(1690, 525)\n",
      "Shape of y_train and y_test:\n",
      "(5068,)\n",
      "(1690,)\n",
      "Shape of imgs_train and imgs_test:\n",
      "(5068,)\n",
      "(1690,)\n",
      "SUCCESS!\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test, y_train, y_test, imgs_train, imgs_test = process_raw_data(l_file, ci_path, \n",
    "    my_random_seed=17, imview=False, test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING SET: \n",
      "{'Pos': 76, 'Neg': 4992, 'TP': 54, 'TN': 4992, 'FP': 0, 'FN': 22, 'Accuracy': 0.9956590370955012, 'Precision': 1.0, 'Recall': 0.7105263157894737, 'desc': 'prc', 'set': 'train'}\n",
      "TEST SET: \n",
      "{'Pos': 25, 'Neg': 1665, 'TP': 13, 'TN': 1665, 'FP': 0, 'FN': 12, 'Accuracy': 0.9928994082840237, 'Precision': 1.0, 'Recall': 0.52, 'desc': 'prc', 'set': 'test'}\n"
     ]
    }
   ],
   "source": [
    "# MODEL: Perceptron\n",
    "from sklearn import linear_model\n",
    "prc = linear_model.SGDClassifier(loss='perceptron')\n",
    "prc.fit(data_train, y_train)\n",
    "\n",
    "prc_performance = BinaryClassificationPerformance(prc.predict(data_train), y_train, 'prc')\n",
    "prc_performance.compute_measures()\n",
    "prc_performance.performance_measures['set'] = 'train'\n",
    "print('TRAINING SET: ')\n",
    "print(prc_performance.performance_measures)\n",
    "\n",
    "prc_performance_test = BinaryClassificationPerformance(prc.predict(data_test), y_test, 'prc')\n",
    "prc_performance_test.compute_measures()\n",
    "prc_performance_test.performance_measures['set'] = 'test'\n",
    "print('TEST SET: ')\n",
    "print(prc_performance_test.performance_measures)\n",
    "\n",
    "prc_performance_test.img_indices()\n",
    "prc_img_indices_to_view = prc_performance_test.image_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_examples(typ, measures):\n",
    "    iiv = ''\n",
    "    if typ == 'FP':\n",
    "        iiv = typ + '_indices'\n",
    "    elif typ == 'TP':\n",
    "        iiv = typ + '_indices'\n",
    "    elif typ == 'FN':\n",
    "        iiv = typ + '_indices'\n",
    "    else:\n",
    "        raise ValueError('input must be \"TP\", \"FP\", or \"FN\"')\n",
    "    for img in measures[iiv]:\n",
    "        warnings.filterwarnings('ignore')    \n",
    "        plt.figure()\n",
    "        lookat = ci_path + imgs_test[img] + '.png' # location of original image\n",
    "        io.imshow(lookat) # show original image\n",
    "        plt.figure()\n",
    "        plt.imshow(data_test[img].reshape(dims[0], dims[1])) # show manipulation for feature representation\n",
    "        warnings.filterwarnings('always')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at examples of Perceptron classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## true positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performance_examples('TP', prc_img_indices_to_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performance_examples('FP', prc_img_indices_to_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performance_examples('FN', prc_img_indices_to_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train Multilayer Perceptron, a.k.a. neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(hidden_layer_sizes=10, max_iter=1000)\n",
      "TRAINING SET: \n",
      "{'Pos': 76, 'Neg': 4992, 'TP': 69, 'TN': 4992, 'FP': 0, 'FN': 7, 'Accuracy': 0.9986187845303868, 'Precision': 1.0, 'Recall': 0.9078947368421053, 'desc': 'nn', 'set': 'train'}\n",
      "TEST SET: \n",
      "{'Pos': 25, 'Neg': 1665, 'TP': 16, 'TN': 1664, 'FP': 1, 'FN': 9, 'Accuracy': 0.9940828402366864, 'Precision': 0.9411764705882353, 'Recall': 0.64, 'desc': 'nn_test', 'set': 'test'}\n"
     ]
    }
   ],
   "source": [
    "# MODEL: Multi-layer Perceptron aka neural network\n",
    "from sklearn import neural_network\n",
    "nn = neural_network.MLPClassifier(hidden_layer_sizes = (10), max_iter=1000)\n",
    "print(nn)\n",
    "nn.fit(data_train, y_train)\n",
    "\n",
    "nn_performance = BinaryClassificationPerformance(nn.predict(data_train), y_train, 'nn')\n",
    "nn_performance.compute_measures()\n",
    "nn_performance.performance_measures['set'] = 'train'\n",
    "print('TRAINING SET: ')\n",
    "print(nn_performance.performance_measures)\n",
    "\n",
    "nn_performance_test = BinaryClassificationPerformance(nn.predict(data_test), y_test, 'nn_test')\n",
    "nn_performance_test.compute_measures()\n",
    "nn_performance_test.performance_measures['set'] = 'test'\n",
    "print('TEST SET: ')\n",
    "print(nn_performance_test.performance_measures)\n",
    "\n",
    "nn_performance_test.img_indices()\n",
    "nn_img_indices_to_view = nn_performance_test.image_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(hidden_layer_sizes=100, max_iter=1000)\n",
      "TRAINING SET: \n",
      "{'Pos': 76, 'Neg': 4992, 'TP': 74, 'TN': 4992, 'FP': 0, 'FN': 2, 'Accuracy': 0.999605367008682, 'Precision': 1.0, 'Recall': 0.9736842105263158, 'desc': 'nn1', 'set': 'train'}\n",
      "TEST SET: \n",
      "{'Pos': 25, 'Neg': 1665, 'TP': 18, 'TN': 1662, 'FP': 3, 'FN': 7, 'Accuracy': 0.9940828402366864, 'Precision': 0.8571428571428571, 'Recall': 0.72, 'desc': 'nn1_test', 'set': 'test'}\n"
     ]
    }
   ],
   "source": [
    "# MODEL: Multi-layer Perceptron aka neural network\n",
    "from sklearn import neural_network\n",
    "nn1 = neural_network.MLPClassifier(hidden_layer_sizes = (100), max_iter=1000)\n",
    "print(nn1)\n",
    "nn1.fit(data_train, y_train)\n",
    "\n",
    "nn1_performance = BinaryClassificationPerformance(nn1.predict(data_train), y_train, 'nn1')\n",
    "nn1_performance.compute_measures()\n",
    "nn1_performance.performance_measures['set'] = 'train'\n",
    "print('TRAINING SET: ')\n",
    "print(nn1_performance.performance_measures)\n",
    "\n",
    "nn1_performance_test = BinaryClassificationPerformance(nn1.predict(data_test), y_test, 'nn1_test')\n",
    "nn1_performance_test.compute_measures()\n",
    "nn1_performance_test.performance_measures['set'] = 'test'\n",
    "print('TEST SET: ')\n",
    "print(nn1_performance_test.performance_measures)\n",
    "\n",
    "nn1_performance_test.img_indices()\n",
    "nn1_img_indices_to_view = nn1_performance_test.image_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(hidden_layer_sizes=1000, max_iter=1000)\n",
      "TRAINING SET: \n",
      "{'Pos': 76, 'Neg': 4992, 'TP': 75, 'TN': 4992, 'FP': 0, 'FN': 1, 'Accuracy': 0.999802683504341, 'Precision': 1.0, 'Recall': 0.9868421052631579, 'desc': 'nn2', 'set': 'train'}\n",
      "TEST SET: \n",
      "{'Pos': 25, 'Neg': 1665, 'TP': 18, 'TN': 1662, 'FP': 3, 'FN': 7, 'Accuracy': 0.9940828402366864, 'Precision': 0.8571428571428571, 'Recall': 0.72, 'desc': 'nn2_test', 'set': 'test'}\n"
     ]
    }
   ],
   "source": [
    "# MODEL: Multi-layer Perceptron aka neural network\n",
    "from sklearn import neural_network\n",
    "nn2 = neural_network.MLPClassifier(hidden_layer_sizes = (1000), max_iter=1000)\n",
    "print(nn2)\n",
    "nn2.fit(data_train, y_train)\n",
    "\n",
    "nn2_performance = BinaryClassificationPerformance(nn2.predict(data_train), y_train, 'nn2')\n",
    "nn2_performance.compute_measures()\n",
    "nn2_performance.performance_measures['set'] = 'train'\n",
    "print('TRAINING SET: ')\n",
    "print(nn2_performance.performance_measures)\n",
    "\n",
    "nn2_performance_test = BinaryClassificationPerformance(nn2.predict(data_test), y_test, 'nn2_test')\n",
    "nn2_performance_test.compute_measures()\n",
    "nn2_performance_test.performance_measures['set'] = 'test'\n",
    "print('TEST SET: ')\n",
    "print(nn2_performance_test.performance_measures)\n",
    "\n",
    "nn2_performance_test.img_indices()\n",
    "nn2_img_indices_to_view = nn2_performance_test.image_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(hidden_layer_sizes=10000, max_iter=1000)\n",
      "TRAINING SET: \n",
      "{'Pos': 76, 'Neg': 4992, 'TP': 76, 'TN': 4992, 'FP': 0, 'FN': 0, 'Accuracy': 1.0, 'Precision': 1.0, 'Recall': 1.0, 'desc': 'nn3', 'set': 'train'}\n",
      "TEST SET: \n",
      "{'Pos': 25, 'Neg': 1665, 'TP': 18, 'TN': 1663, 'FP': 2, 'FN': 7, 'Accuracy': 0.9946745562130177, 'Precision': 0.9, 'Recall': 0.72, 'desc': 'nn3_test', 'set': 'test'}\n"
     ]
    }
   ],
   "source": [
    "# MODEL: Multi-layer Perceptron aka neural network\n",
    "from sklearn import neural_network\n",
    "nn3 = neural_network.MLPClassifier(hidden_layer_sizes = (10000), max_iter=1000)\n",
    "print(nn3)\n",
    "nn3.fit(data_train, y_train)\n",
    "\n",
    "nn3_performance = BinaryClassificationPerformance(nn3.predict(data_train), y_train, 'nn3')\n",
    "nn3_performance.compute_measures()\n",
    "nn3_performance.performance_measures['set'] = 'train'\n",
    "print('TRAINING SET: ')\n",
    "print(nn3_performance.performance_measures)\n",
    "\n",
    "nn3_performance_test = BinaryClassificationPerformance(nn3.predict(data_test), y_test, 'nn3_test')\n",
    "nn3_performance_test.compute_measures()\n",
    "nn3_performance_test.performance_measures['set'] = 'test'\n",
    "print('TEST SET: ')\n",
    "print(nn3_performance_test.performance_measures)\n",
    "\n",
    "nn3_performance_test.img_indices()\n",
    "nn3_img_indices_to_view = nn3_performance_test.image_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(hidden_layer_sizes=100000, max_iter=1000)\n"
     ]
    }
   ],
   "source": [
    "# MODEL: Multi-layer Perceptron aka neural network\n",
    "from sklearn import neural_network\n",
    "nn4 = neural_network.MLPClassifier(hidden_layer_sizes = (100000), max_iter=1000)\n",
    "print(nn4)\n",
    "nn4.fit(data_train, y_train)\n",
    "\n",
    "nn4_performance = BinaryClassificationPerformance(nn4.predict(data_train), y_train, 'nn4')\n",
    "nn4_performance.compute_measures()\n",
    "nn4_performance.performance_measures['set'] = 'train'\n",
    "print('TRAINING SET: ')\n",
    "print(nn4_performance.performance_measures)\n",
    "\n",
    "nn4_performance_test = BinaryClassificationPerformance(nn4.predict(data_test), y_test, 'nn4_test')\n",
    "nn4_performance_test.compute_measures()\n",
    "nn4_performance_test.performance_measures['set'] = 'test'\n",
    "print('TEST SET: ')\n",
    "print(nn4_performance_test.performance_measures)\n",
    "\n",
    "nn4_performance_test.img_indices()\n",
    "nn4_img_indices_to_view = nn4_performance_test.image_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(hidden_layer_sizes=1000000, max_iter=1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chooseimage/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:619: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    }
   ],
   "source": [
    "# MODEL: Multi-layer Perceptron aka neural network\n",
    "\n",
    "'''\n",
    "from sklearn import neural_network\n",
    "nn5 = neural_network.MLPClassifier(hidden_layer_sizes = (1000000), max_iter=1000)\n",
    "print(nn5)\n",
    "nn5.fit(data_train, y_train)\n",
    "\n",
    "nn5_performance = BinaryClassificationPerformance(nn5.predict(data_train), y_train, 'nn5')\n",
    "nn5_performance.compute_measures()\n",
    "nn5_performance.performance_measures['set'] = 'train'\n",
    "print('TRAINING SET: ')\n",
    "print(nn5_performance.performance_measures)\n",
    "\n",
    "nn5_performance_test = BinaryClassificationPerformance(nn5.predict(data_test), y_test, 'nn5_test')\n",
    "nn5_performance_test.compute_measures()\n",
    "nn5_performance_test.performance_measures['set'] = 'test'\n",
    "print('TEST SET: ')\n",
    "print(nn5_performance_test.performance_measures)\n",
    "\n",
    "nn5_performance_test.img_indices()\n",
    "nn5_img_indices_to_view = nn5_performance_test.image_indices\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nLayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# MODEL: Multi-layer Perceptron aka neural network\n",
    "from sklearn import neural_network\n",
    "nn6 = neural_network.MLPClassifier(hidden_layer_sizes = (1000), max_iter=1000)\n",
    "print(nn6)\n",
    "nn6.fit(data_train, y_train)\n",
    "\n",
    "nn6_performance = BinaryClassificationPerformance(nn6.predict(data_train), y_train, 'nn6')\n",
    "nn6_performance.compute_measures()\n",
    "nn6_performance.performance_measures['set'] = 'train'\n",
    "print('TRAINING SET: ')\n",
    "print(nn6_performance.performance_measures)\n",
    "\n",
    "nn6_performance_test = BinaryClassificationPerformance(nn6.predict(data_test), y_test, 'nn6_test')\n",
    "nn6_performance_test.compute_measures()\n",
    "nn6_performance_test.performance_measures['set'] = 'test'\n",
    "print('TEST SET: ')\n",
    "print(nn6_performance_test.performance_measures)\n",
    "\n",
    "nn6_performance_test.img_indices()\n",
    "nn6_img_indices_to_view = nn6_performance_test.image_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# MODEL: Multi-layer Perceptron aka neural network\n",
    "from sklearn import neural_network\n",
    "nn7 = neural_network.MLPClassifier(hidden_layer_sizes = (1000, 1000), max_iter=1000)\n",
    "print(nn7)\n",
    "nn7.fit(data_train, y_train)\n",
    "\n",
    "nn7_performance = BinaryClassificationPerformance(nn7.predict(data_train), y_train, 'nn7')\n",
    "nn7_performance.compute_measures()\n",
    "nn7_performance.performance_measures['set'] = 'train'\n",
    "print('TRAINING SET: ')\n",
    "print(nn7_performance.performance_measures)\n",
    "\n",
    "nn7_performance_test = BinaryClassificationPerformance(nn7.predict(data_test), y_test, 'nn7_test')\n",
    "nn7_performance_test.compute_measures()\n",
    "nn7_performance_test.performance_measures['set'] = 'test'\n",
    "print('TEST SET: ')\n",
    "print(nn7_performance_test.performance_measures)\n",
    "\n",
    "nn7_performance_test.img_indices()\n",
    "nn7_img_indices_to_view = nn7_performance_test.image_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# MODEL: Multi-layer Perceptron aka neural network\n",
    "from sklearn import neural_network\n",
    "nn8 = neural_network.MLPClassifier(hidden_layer_sizes = (1000, 1000, 1000), max_iter=1000)\n",
    "print(nn8)\n",
    "nn8.fit(data_train, y_train)\n",
    "\n",
    "nn8_performance = BinaryClassificationPerformance(nn8.predict(data_train), y_train, 'nn8')\n",
    "nn8_performance.compute_measures()\n",
    "nn8_performance.performance_measures['set'] = 'train'\n",
    "print('TRAINING SET: ')\n",
    "print(nn8_performance.performance_measures)\n",
    "\n",
    "nn8_performance_test = BinaryClassificationPerformance(nn8.predict(data_test), y_test, 'nn8_test')\n",
    "nn8_performance_test.compute_measures()\n",
    "nn8_performance_test.performance_measures['set'] = 'test'\n",
    "print('TEST SET: ')\n",
    "print(nn8_performance_test.performance_measures)\n",
    "\n",
    "nn8_performance_test.img_indices()\n",
    "nn8_img_indices_to_view = nn8_performance_test.image_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# MODEL: Multi-layer Perceptron aka neural network\n",
    "from sklearn import neural_network\n",
    "nn9 = neural_network.MLPClassifier(hidden_layer_sizes = (1000, 1000, 1000, 1000), max_iter=1000)\n",
    "print(nn9)\n",
    "nn9.fit(data_train, y_train)\n",
    "\n",
    "nn9_performance = BinaryClassificationPerformance(nn9.predict(data_train), y_train, 'nn9')\n",
    "nn9_performance.compute_measures()\n",
    "nn9_performance.performance_measures['set'] = 'train'\n",
    "print('TRAINING SET: ')\n",
    "print(nn9_performance.performance_measures)\n",
    "\n",
    "nn9_performance_test = BinaryClassificationPerformance(nn9.predict(data_test), y_test, 'nn9_test')\n",
    "nn9_performance_test.compute_measures()\n",
    "nn9_performance_test.performance_measures['set'] = 'test'\n",
    "print('TEST SET: ')\n",
    "print(nn9_performance_test.performance_measures)\n",
    "\n",
    "nn9_performance_test.img_indices()\n",
    "nn9_img_indices_to_view = nn9_performance_test.image_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# MODEL: Multi-layer Perceptron aka neural network\n",
    "'''\n",
    "from sklearn import neural_network\n",
    "nnx = neural_network.MLPClassifier(hidden_layer_sizes = (1000, 1000, 1000, 1000, 1000), max_iter=1000)\n",
    "print(nnx)\n",
    "nnx.fit(data_train, y_train)\n",
    "\n",
    "nnx_performance = BinaryClassificationPerformance(nnx.predict(data_train), y_train, 'nnx')\n",
    "nnx_performance.compute_measures()\n",
    "nnx_performance.performance_measures['set'] = 'train'\n",
    "print('TRAINING SET: ')\n",
    "print(nnx_performance.performance_measures)\n",
    "\n",
    "nnx_performance_test = BinaryClassificationPerformance(nnx.predict(data_test), y_test, 'nnx_test')\n",
    "nnx_performance_test.compute_measures()\n",
    "nnx_performance_test.performance_measures['set'] = 'test'\n",
    "print('TEST SET: ')\n",
    "print(nnx_performance_test.performance_measures)\n",
    "\n",
    "nnx_performance_test.img_indices()\n",
    "nnx_img_indices_to_view = nnx_performance_test.image_indices\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# MODEL: Multi-layer Perceptron aka neural network\n",
    "'''\n",
    "from sklearn import neural_network\n",
    "nnxi = neural_network.MLPClassifier(hidden_layer_sizes = (1000, 1000, 1000, 1000, 1000, 1000), max_iter=1000)\n",
    "print(nnxi)\n",
    "nnxi.fit(data_train, y_train)\n",
    "\n",
    "nnxi_performance = BinaryClassificationPerformance(nnxi.predict(data_train), y_train, 'nnxi')\n",
    "nnxi_performance.compute_measures()\n",
    "nnxi_performance.performance_measures['set'] = 'train'\n",
    "print('TRAINING SET: ')\n",
    "print(nnxi_performance.performance_measures)\n",
    "\n",
    "nnxi_performance_test = BinaryClassificationPerformance(nnxi.predict(data_test), y_test, 'nnxi_test')\n",
    "nnxi_performance_test.compute_measures()\n",
    "nnxi_performance_test.performance_measures['set'] = 'test'\n",
    "print('TEST SET: ')\n",
    "print(nnxi_performance_test.performance_measures)\n",
    "\n",
    "nnxi_performance_test.img_indices()\n",
    "nnxi_img_indices_to_view = nnxi_performance_test.image_indices\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at examples of neural network classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## true positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performance_examples('TP', nn_img_indices_to_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performance_examples('FP', nn_img_indices_to_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performance_examples('FN', nn_img_indices_to_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of fits to compare: \n",
    "final_fits = []\n",
    "final_fits.append(prc_performance.performance_measures)\n",
    "final_fits.append(prc_performance_test.performance_measures)\n",
    "final_fits.append(nn_performance.performance_measures)\n",
    "final_fits.append(nn_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "for fit in final_fits:\n",
    "    if fit['set'] == 'train':\n",
    "        color = 'co'\n",
    "    else:\n",
    "        color = 'ro'\n",
    "    plt.plot(fit['FP'] / fit['Neg'], \n",
    "             fit['TP'] / fit['Pos'], color, markersize=12)\n",
    "    plt.text(fit['FP'] / fit['Neg'], \n",
    "             fit['TP'] / fit['Pos'], fit['desc'] + ': ' + fit['set'], fontsize=16)\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.title('ROC plot: test set')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of fits to compare: \n",
    "final_fits = []\n",
    "final_fits.append(prc_performance.performance_measures)\n",
    "final_fits.append(prc_performance_test.performance_measures)\n",
    "final_fits.append(nn_performance.performance_measures)\n",
    "final_fits.append(nn_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of fits to compare:\n",
    "final_fitsN = []\n",
    "final_fitsN.append(nn_performance.performance_measures)\n",
    "final_fitsN.append(nn_performance_test.performance_measures)\n",
    "\n",
    "final_fitsN.append(nn1_performance.performance_measures)\n",
    "final_fitsN.append(nn1_performance_test.performance_measures)\n",
    "\n",
    "final_fitsN.append(nn2_performance.performance_measures)\n",
    "final_fitsN.append(nn2_performance_test.performance_measures)\n",
    "\n",
    "final_fitsN.append(nn3_performance.performance_measures)\n",
    "final_fitsN.append(nn3_performance_test.performance_measures)\n",
    "\n",
    "#final_fitsN.append(nn4_performance.performance_measures)\n",
    "#final_fitsN.append(nn4_performance_test.performance_measures)\n",
    "\n",
    "#final_fitsN.append(nn5_performance.performance_measures)\n",
    "#final_fitsN.append(nn5_performance_test.performance_measures)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "for fit in final_fitsN:\n",
    "    if fit['set'] == 'train':\n",
    "        color = 'co'\n",
    "    else:\n",
    "        color = 'ro'\n",
    "    plt.plot(fit['FP'] / fit['Neg'], \n",
    "             fit['TP'] / fit['Pos'], color, markersize=12)\n",
    "    plt.text(fit['FP'] / fit['Neg'], \n",
    "             fit['TP'] / fit['Pos'], fit['desc'] + ': ' + fit['set'], fontsize=16)\n",
    "plt.axis([0, 0.01, 0.6, 1])\n",
    "plt.title('ROC plot: test set')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of fits to compare: \n",
    "final_fitsL = []\n",
    "final_fitsL.append(nn6_performance.performance_measures)\n",
    "final_fitsL.append(nn6_performance_test.performance_measures)\n",
    "\n",
    "final_fitsL.append(nn7_performance.performance_measures)\n",
    "final_fitsL.append(nn7_performance_test.performance_measures)\n",
    "\n",
    "final_fitsL.append(nn8_performance.performance_measures)\n",
    "final_fitsL.append(nn8_performance_test.performance_measures)\n",
    "\n",
    "final_fitsL.append(nn9_performance.performance_measures)\n",
    "final_fitsL.append(nn9_performance_test.performance_measures)\n",
    "\n",
    "#final_fitsL.append(nnx_performance.performance_measures)\n",
    "#final_fitsL.append(nnx_performance_test.performance_measures)\n",
    "\n",
    "#final_fitsL.append(nnxi_performance.performance_measures)\n",
    "#final_fitsL.append(nnxi_performance_test.performance_measures)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "for fit in final_fitsL:\n",
    "    if fit['set'] == 'train':\n",
    "        color = 'co'\n",
    "    else:\n",
    "        color = 'ro'\n",
    "    plt.plot(fit['FP'] / fit['Neg'], \n",
    "             fit['TP'] / fit['Pos'], color, markersize=12)\n",
    "    plt.text(fit['FP'] / fit['Neg'], \n",
    "             fit['TP'] / fit['Pos'], fit['desc'] + ': ' + fit['set'], fontsize=16)\n",
    "plt.axis([0, 0.01, 0.6, 1])\n",
    "plt.title('ROC plot: test set')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUBMISSION\n",
    "\n",
    "### file paths and names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_ci_path = 'test_data_for_grading/test_cropped_images/' # file path for cropped images for training\n",
    "submission_l_file = 'test_data_for_grading/test_plane_labels.csv' # file path and file name for csv with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few lines of image labels: \n",
      "                   img_name\n",
      "0  2016-08-02T13+50+24_430Z\n",
      "1  2016-08-02T14+12+37_390Z\n",
      "2  2016-08-03T12+32+21_790Z\n",
      "3  2016-08-03T13+19+28_320Z\n",
      "4  2016-08-05T15+24+58_670Z\n",
      "Size of image label dataFrame: \n",
      "(1523, 1)\n",
      "Shape of original feature representation: \n",
      "(1523, 15, 35)\n",
      "Shape of flat feature representation: \n",
      "(1523, 525)\n",
      "Shape of X_test for submission:\n",
      "(1523, 525)\n",
      "SUCCESS!\n",
      "Number of rows in the submission test set (should be 1,523): \n"
     ]
    }
   ],
   "source": [
    "X_test_data, X_test_submission = process_raw_data(submission_l_file, submission_ci_path, my_random_seed=74, test=True)\n",
    "print(\"Number of rows in the submission test set (should be 1,523): \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT CHECK: make sure that the number of columns in your training data is the same as the number of columns in this test submission!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5068, 525)\n",
      "(1523, 525)\n"
     ]
    }
   ],
   "source": [
    "print(data_train.shape)\n",
    "print(X_test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the training set and submission test set have 525 columns. Success!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Choose a *single* model for your submission. In this code, I am choosing the Perceptron model fit, which is in the prc object. But you should choose the model that is performing the best for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016414970453053186\n"
     ]
    }
   ],
   "source": [
    "# concatenate predictions to the id\n",
    "X_test_submission[\"prediction\"] = prc.predict(X_test_data)\n",
    "# look at the proportion of positive predictions\n",
    "print(X_test_submission['prediction'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the proportion of predictions that have predicted that there is an airplane in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1523, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_submission.shape) # should be (1523, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export submission file as pdf\n",
    "# CHANGE FILE PATH: \n",
    "X_test_submission.to_csv('airplane_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
